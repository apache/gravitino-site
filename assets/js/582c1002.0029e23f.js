"use strict";(self.webpackChunkapache_website_template=self.webpackChunkapache_website_template||[]).push([[1408],{87612:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var n=i(13274),s=i(43183);const a={title:"How to use Apache Gravitino Virtual File System with Filesets",slug:"/how-to-use-gvfs",license:"This software is licensed under the Apache License version 2."},r=void 0,o={id:"how-to-use-gvfs",title:"How to use Apache Gravitino Virtual File System with Filesets",description:"Introduction",source:"@site/versioned_docs/version-0.6.1-incubating/how-to-use-gvfs.md",sourceDirName:".",slug:"/how-to-use-gvfs",permalink:"/docs/0.6.1-incubating/how-to-use-gvfs",draft:!1,unlisted:!1,editUrl:"https://github.com/apache/gravitino-site/tree/main/docs/how-to-use-gvfs.md",tags:[],version:"0.6.1-incubating",lastUpdatedBy:"Qian Xia",lastUpdatedAt:1729496081e3,frontMatter:{title:"How to use Apache Gravitino Virtual File System with Filesets",slug:"/how-to-use-gvfs",license:"This software is licensed under the Apache License version 2."},sidebar:"docs",previous:{title:"Manage fileset metadata",permalink:"/docs/0.6.1-incubating/manage-fileset-metadata-using-gravitino"},next:{title:"Manage messaging metadata",permalink:"/docs/0.6.1-incubating/manage-massaging-metadata-using-gravitino"}},l={},h=[{value:"Introduction",id:"introduction",level:2},{value:"1. Managing files of Fileset with Java GVFS",id:"1-managing-files-of-fileset-with-java-gvfs",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Usage examples",id:"usage-examples",level:3},{value:"Via Hadoop shell command",id:"via-hadoop-shell-command",level:4},{value:"Via Java code",id:"via-java-code",level:4},{value:"Via Apache Spark",id:"via-apache-spark",level:4},{value:"Via Tensorflow",id:"via-tensorflow",level:4},{value:"Authentication",id:"authentication",level:3},{value:"How to use authentication",id:"how-to-use-authentication",level:4},{value:"Using <code>simple</code> authentication",id:"using-simple-authentication",level:5},{value:"Using <code>OAuth</code> authentication",id:"using-oauth-authentication",level:5},{value:"Using <code>Kerberos</code> authentication",id:"using-kerberos-authentication",level:5},{value:"2. Managing files of Fileset with Python GVFS",id:"2-managing-files-of-fileset-with-python-gvfs",level:2},{value:"Prerequisites",id:"prerequisites-1",level:3},{value:"Configuration",id:"configuration-1",level:3},{value:"Usage examples",id:"usage-examples-1",level:3},{value:"Via fsspec-style interface",id:"via-fsspec-style-interface",level:4},{value:"Integrating with Third-party Python libraries",id:"integrating-with-third-party-python-libraries",level:4},{value:"Authentication",id:"authentication-1",level:3},{value:"How to use authentication",id:"how-to-use-authentication-1",level:4},{value:"Using <code>simple</code> authentication",id:"using-simple-authentication-1",level:5}];function c(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.code,{children:"Fileset"})," is a concept brought in by Apache Gravitino, which is a logical collection of files and\ndirectories, with ",(0,n.jsx)(t.code,{children:"fileset"})," you can manage non-tabular data through Gravitino. For\ndetails, you can read ",(0,n.jsx)(t.a,{href:"/docs/0.6.1-incubating/manage-fileset-metadata-using-gravitino",children:"How to manage fileset metadata using Gravitino"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["To use ",(0,n.jsx)(t.code,{children:"Fileset"})," managed by Gravitino, Gravitino provides a virtual file system layer called\nthe Gravitino Virtual File System (GVFS):"]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"In Java, it's built on top of the Hadoop Compatible File System(HCFS) interface."}),"\n",(0,n.jsxs)(t.li,{children:["In Python, it's built on top of the ",(0,n.jsx)(t.a,{href:"https://filesystem-spec.readthedocs.io/en/stable/index.html",children:"fsspec"}),"\ninterface."]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"GVFS is a virtual layer that manages the files and directories in the fileset through a virtual\npath, without needing to understand the specific storage details of the fileset. You can access\nthe files or folders as shown below:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-text",children:"gvfs://fileset/${catalog_name}/${schema_name}/${fileset_name}/sub_dir/\n"})}),"\n",(0,n.jsx)(t.p,{children:"In python GVFS, you can also access the files or folders as shown below:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-text",children:"fileset/${catalog_name}/${schema_name}/${fileset_name}/sub_dir/\n"})}),"\n",(0,n.jsxs)(t.p,{children:["Here ",(0,n.jsx)(t.code,{children:"gvfs"})," is the scheme of the GVFS, ",(0,n.jsx)(t.code,{children:"fileset"})," is the root directory of the GVFS which can't\nmodified, and ",(0,n.jsx)(t.code,{children:"${catalog_name}/${schema_name}/${fileset_name}"})," is the virtual path of the fileset.\nYou can access the files and folders under this virtual path by concatenating a file or folder\nname to the virtual path."]}),"\n",(0,n.jsx)(t.p,{children:"The usage pattern for GVFS is the same as HDFS or S3. GVFS internally manages\nthe path mapping and convert automatically."}),"\n",(0,n.jsx)(t.h2,{id:"1-managing-files-of-fileset-with-java-gvfs",children:"1. Managing files of Fileset with Java GVFS"}),"\n",(0,n.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["A Hadoop environment with HDFS running. GVFS has been tested against\nHadoop 3.1.0. It is recommended to use Hadoop 3.1.0 or later, but it should work with Hadoop 2.\nx. Please create an ",(0,n.jsx)(t.a,{href:"https://www.github.com/apache/gravitino/issues",children:"issue"})," if you find any\ncompatibility issues."]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"configuration",children:"Configuration"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Configuration item"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Default value"}),(0,n.jsx)(t.th,{children:"Required"}),(0,n.jsx)(t.th,{children:"Since version"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.AbstractFileSystem.gvfs.impl"})}),(0,n.jsxs)(t.td,{children:["The Gravitino Virtual File System abstract class, set it to ",(0,n.jsx)(t.code,{children:"org.apache.gravitino.filesystem.hadoop.Gvfs"}),"."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gvfs.impl"})}),(0,n.jsxs)(t.td,{children:["The Gravitino Virtual File System implementation class, set it to ",(0,n.jsx)(t.code,{children:"org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem"}),"."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gvfs.impl.disable.cache"})}),(0,n.jsxs)(t.td,{children:["Disable the Gravitino Virtual File System cache in the Hadoop environment. If you need to proxy multi-user operations, please set this value to ",(0,n.jsx)(t.code,{children:"true"})," and create a separate File System for each user."]}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"false"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.server.uri"})}),(0,n.jsx)(t.td,{children:"The Gravitino server URI which GVFS needs to load the fileset metadata."}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.metalake"})}),(0,n.jsx)(t.td,{children:"The metalake to which the fileset belongs."}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.authType"})}),(0,n.jsxs)(t.td,{children:["The auth type to initialize the Gravitino client to use with the Gravitino Virtual File System. Currently only supports ",(0,n.jsx)(t.code,{children:"simple"}),", ",(0,n.jsx)(t.code,{children:"oauth2"})," and ",(0,n.jsx)(t.code,{children:"kerberos"})," auth types."]}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"simple"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.oauth2.serverUri"})}),(0,n.jsxs)(t.td,{children:["The auth server URI for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type with the Gravitino Virtual File System."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsxs)(t.td,{children:["Yes if you use ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type"]}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.oauth2.credential"})}),(0,n.jsxs)(t.td,{children:["The auth credential for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type in the Gravitino Virtual File System."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsxs)(t.td,{children:["Yes if you use ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type"]}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.oauth2.path"})}),(0,n.jsxs)(t.td,{children:["The auth server path for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type with the Gravitino Virtual File System. Please remove the first slash ",(0,n.jsx)(t.code,{children:"/"})," from the path, for example ",(0,n.jsx)(t.code,{children:"oauth/token"}),"."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsxs)(t.td,{children:["Yes if you use ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type"]}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.oauth2.scope"})}),(0,n.jsxs)(t.td,{children:["The auth scope for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type with the Gravitino Virtual File System."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsxs)(t.td,{children:["Yes if you use ",(0,n.jsx)(t.code,{children:"oauth2"})," auth type"]}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.kerberos.principal"})}),(0,n.jsxs)(t.td,{children:["The auth principal for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"kerberos"})," auth type with the Gravitino Virtual File System."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsxs)(t.td,{children:["Yes if you use ",(0,n.jsx)(t.code,{children:"kerberos"})," auth type"]}),(0,n.jsx)(t.td,{children:"0.5.1"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.client.kerberos.keytabFilePath"})}),(0,n.jsxs)(t.td,{children:["The auth keytab file path for the Gravitino client when using ",(0,n.jsx)(t.code,{children:"kerberos"})," auth type in the Gravitino Virtual File System."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.5.1"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.fileset.cache.maxCapacity"})}),(0,n.jsx)(t.td,{children:"The cache capacity of the Gravitino Virtual File System."}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"20"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.5.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"fs.gravitino.fileset.cache.evictionMillsAfterAccess"})}),(0,n.jsxs)(t.td,{children:["The value of time that the cache expires after accessing in the Gravitino Virtual File System. The value is in ",(0,n.jsx)(t.code,{children:"milliseconds"}),"."]}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"3600000"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.5.0"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"You can configure these properties in two ways:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Before obtaining the ",(0,n.jsx)(t.code,{children:"FileSystem"})," in the code, construct a ",(0,n.jsx)(t.code,{children:"Configuration"})," object and set its properties:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-java",children:'Configuration conf = new Configuration();\nconf.set("fs.AbstractFileSystem.gvfs.impl","org.apache.gravitino.filesystem.hadoop.Gvfs");\nconf.set("fs.gvfs.impl","org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");\nconf.set("fs.gravitino.server.uri","http://localhost:8090");\nconf.set("fs.gravitino.client.metalake","test_metalake");\nPath filesetPath = new Path("gvfs://fileset/test_catalog/test_schema/test_fileset_1");\nFileSystem fs = filesetPath.getFileSystem(conf);\n'})}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Configure the properties in the ",(0,n.jsx)(t.code,{children:"core-site.xml"})," file of the Hadoop environment:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-xml",children:"  <property>\n    <name>fs.AbstractFileSystem.gvfs.impl</name>\n    <value>org.apache.gravitino.filesystem.hadoop.Gvfs</value>\n  </property>\n\n  <property>\n    <name>fs.gvfs.impl</name>\n    <value>org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem</value>\n  </property>\n\n  <property>\n    <name>fs.gravitino.server.uri</name>\n    <value>http://localhost:8090</value>\n  </property>\n\n  <property>\n    <name>fs.gravitino.client.metalake</name>\n    <value>test_metalake</value>\n  </property>\n"})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"usage-examples",children:"Usage examples"}),"\n",(0,n.jsx)(t.p,{children:"First make sure to obtain the Gravitino Virtual File System runtime jar, which you can get in\ntwo ways:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Download from the maven central repository. You can download the runtime jar named\n",(0,n.jsx)(t.code,{children:"gravitino-filesystem-hadoop3-runtime-{version}.jar"})," from ",(0,n.jsx)(t.a,{href:"https://mvnrepository.com/",children:"Maven repository"}),"."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Compile from the source code:"}),"\n",(0,n.jsxs)(t.p,{children:["Download or clone the ",(0,n.jsx)(t.a,{href:"https://github.com/apache/gravitino",children:"Gravitino source code"}),", and compile it\nlocally using the following command in the Gravitino source code directory:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"   ./gradlew :clients:filesystem-hadoop3-runtime:build -x test\n"})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"via-hadoop-shell-command",children:"Via Hadoop shell command"}),"\n",(0,n.jsx)(t.p,{children:"You can use the Hadoop shell command to perform operations on the fileset storage. For example:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"# 1. Configure the hadoop `core-site.xml` configuration\n# You should put the required properties into this file\nvi ${HADOOP_HOME}/etc/hadoop/core-site.xml\n\n# 2. Place the GVFS runtime jar into your Hadoop environment\ncp gravitino-filesystem-hadoop3-runtime-{version}.jar ${HADOOP_HOME}/share/hadoop/common/lib/\n\n# 3. Complete the Kerberos authentication setup of the Hadoop environment (if necessary).\n# You need to ensure that the Kerberos has permission on the HDFS directory.\nkinit -kt your_kerberos.keytab your_kerberos@xxx.com\n\n# 4. Try to list the fileset\n./${HADOOP_HOME}/bin/hadoop dfs -ls gvfs://fileset/test_catalog/test_schema/test_fileset_1\n"})}),"\n",(0,n.jsx)(t.h4,{id:"via-java-code",children:"Via Java code"}),"\n",(0,n.jsxs)(t.p,{children:["You can also perform operations on the files or directories managed by fileset through Java code.\nMake sure that your code is using the correct Hadoop environment, and that your environment\nhas the ",(0,n.jsx)(t.code,{children:"gravitino-filesystem-hadoop3-runtime-{version}.jar"})," dependency."]}),"\n",(0,n.jsx)(t.p,{children:"For example:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-java",children:'Configuration conf = new Configuration();\nconf.set("fs.AbstractFileSystem.gvfs.impl","org.apache.gravitino.filesystem.hadoop.Gvfs");\nconf.set("fs.gvfs.impl","org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");\nconf.set("fs.gravitino.server.uri","http://localhost:8090");\nconf.set("fs.gravitino.client.metalake","test_metalake");\nPath filesetPath = new Path("gvfs://fileset/test_catalog/test_schema/test_fileset_1");\nFileSystem fs = filesetPath.getFileSystem(conf);\nfs.getFileStatus(filesetPath);\n'})}),"\n",(0,n.jsx)(t.h4,{id:"via-apache-spark",children:"Via Apache Spark"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Add the GVFS runtime jar to the Spark environment."}),"\n",(0,n.jsxs)(t.p,{children:["You can use ",(0,n.jsx)(t.code,{children:"--packages"})," or ",(0,n.jsx)(t.code,{children:"--jars"})," in the Spark submit shell to include the Gravitino Virtual\nFile System runtime jar, like so:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"./${SPARK_HOME}/bin/spark-submit --packages org.apache.gravitino:filesystem-hadoop3-runtime:${version}\n"})}),"\n",(0,n.jsxs)(t.p,{children:["If you want to include the Gravitino Virtual File System runtime jar in your Spark installation, add it to the ",(0,n.jsx)(t.code,{children:"${SPARK_HOME}/jars/"})," folder."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Configure the Hadoop configuration when submitting the job."}),"\n",(0,n.jsx)(t.p,{children:"You can configure in the shell command in this way:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"--conf spark.hadoop.fs.AbstractFileSystem.gvfs.impl=org.apache.gravitino.filesystem.hadoop.Gvfs\n--conf spark.hadoop.fs.gvfs.impl=org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem\n--conf spark.hadoop.fs.gravitino.server.uri=${your_gravitino_server_uri}\n--conf spark.hadoop.fs.gravitino.client.metalake=${your_gravitino_metalake}\n"})}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Perform operations on the fileset storage in your code."}),"\n",(0,n.jsx)(t.p,{children:"Finally, you can access the fileset storage in your Spark program:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'// Scala code\nval spark = SparkSession.builder()\n      .appName("Gvfs Example")\n      .getOrCreate()\n\nval rdd = spark.sparkContext.textFile("gvfs://fileset/test_catalog/test_schema/test_fileset_1")\n\nrdd.foreach(println)\n'})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"via-tensorflow",children:"Via Tensorflow"}),"\n",(0,n.jsxs)(t.p,{children:["For Tensorflow to support GVFS, you need to recompile the ",(0,n.jsx)(t.a,{href:"https://github.com/tensorflow/io",children:"tensorflow-io"})," module."]}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"First, add a patch and recompile tensorflow-io."}),"\n",(0,n.jsxs)(t.p,{children:["You need to add a ",(0,n.jsx)(t.a,{href:"https://github.com/tensorflow/io/pull/1970",children:"patch"})," to support GVFS on\ntensorflow-io. Then you can follow the ",(0,n.jsx)(t.a,{href:"https://github.com/tensorflow/io/blob/master/docs/development.md",children:"tutorial"}),"\nto recompile your code and release the tensorflow-io module."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Then you need to configure the Hadoop configuration."}),"\n",(0,n.jsxs)(t.p,{children:["You need to configure the Hadoop configuration and add ",(0,n.jsx)(t.code,{children:"gravitino-filesystem-hadoop3-runtime-{version}.jar"}),",\nand set up the Kerberos environment according to the ",(0,n.jsx)(t.a,{href:"#use-gvfs-via-hadoop-shell-command",children:"Use GVFS via Hadoop shell command"})," sections."]}),"\n",(0,n.jsx)(t.p,{children:"Then you need to set your environment as follows:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'export HADOOP_HOME=${your_hadoop_home}\nexport HADOOP_CONF_DIR=${your_hadoop_conf_home}\nexport PATH=$PATH:$HADOOP_HOME/libexec/hadoop-config.sh\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_HOME/jre/lib/amd64/server\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\nexport CLASSPATH="$(hadoop classpath --glob)"\n'})}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Import tensorflow-io and test."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"import tensorflow as tf\nimport tensorflow_io as tfio\n\n## read a file\nprint(tf.io.read_file('gvfs://fileset/test_catalog/test_schema/test_fileset_1/test.txt'))\n\n## list directory\nprint(tf.io.gfile.listdir('gvfs://fileset/test_catalog/test_schema/test_fileset_1/'))\n"})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"authentication",children:"Authentication"}),"\n",(0,n.jsxs)(t.p,{children:["Currently, Gravitino Virtual File System supports two kinds of authentication types to access Gravitino server: ",(0,n.jsx)(t.code,{children:"simple"})," and ",(0,n.jsx)(t.code,{children:"oauth2"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["The type of ",(0,n.jsx)(t.code,{children:"simple"})," is the default authentication type in Gravitino Virtual File System."]}),"\n",(0,n.jsx)(t.h4,{id:"how-to-use-authentication",children:"How to use authentication"}),"\n",(0,n.jsxs)(t.h5,{id:"using-simple-authentication",children:["Using ",(0,n.jsx)(t.code,{children:"simple"})," authentication"]}),"\n",(0,n.jsxs)(t.p,{children:["First, make sure that your Gravitino server is also configured to use the ",(0,n.jsx)(t.code,{children:"simple"})," authentication mode."]}),"\n",(0,n.jsx)(t.p,{children:"Then, you can configure the Hadoop configuration like this:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-java",children:'// Simple type uses the environment variable `GRAVITINO_USER` as the client user.\n// If the environment variable `GRAVITINO_USER` isn\'t set,\n// the client uses the user of the machine that sends requests.\nSystem.setProperty("GRAVITINO_USER", "test");\n\nConfiguration conf = new Configuration();\nconf.set("fs.AbstractFileSystem.gvfs.impl","org.apache.gravitino.filesystem.hadoop.Gvfs");\nconf.set("fs.gvfs.impl","org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");\nconf.set("fs.gravitino.server.uri","http://localhost:8090");\nconf.set("fs.gravitino.client.metalake","test_metalake");\n// Configure the auth type to simple,\n// or do not configure this configuration, gvfs will use simple type as default.\nconf.set("fs.gravitino.client.authType", "simple");\nPath filesetPath = new Path("gvfs://fileset/test_catalog/test_schema/test_fileset_1");\nFileSystem fs = filesetPath.getFileSystem(conf);\n'})}),"\n",(0,n.jsxs)(t.h5,{id:"using-oauth-authentication",children:["Using ",(0,n.jsx)(t.code,{children:"OAuth"})," authentication"]}),"\n",(0,n.jsxs)(t.p,{children:["If you want to use ",(0,n.jsx)(t.code,{children:"oauth2"})," authentication for the Gravitino client in the Gravitino Virtual File System,\nplease refer to this document to complete the configuration of the Gravitino server and the OAuth server: ",(0,n.jsx)(t.a,{href:"/docs/0.6.1-incubating/security/security",children:"Security"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"Then, you can configure the Hadoop configuration like this:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-java",children:'Configuration conf = new Configuration();\nconf.set("fs.AbstractFileSystem.gvfs.impl","org.apache.gravitino.filesystem.hadoop.Gvfs");\nconf.set("fs.gvfs.impl","org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");\nconf.set("fs.gravitino.server.uri","http://localhost:8090");\nconf.set("fs.gravitino.client.metalake","test_metalake");\n// Configure the auth type to oauth2.\nconf.set("fs.gravitino.client.authType", "oauth2");\n// Configure the OAuth configuration.\nconf.set("fs.gravitino.client.oauth2.serverUri", "${your_oauth_server_uri}");\nconf.set("fs.gravitino.client.oauth2.credential", "${your_client_credential}");\nconf.set("fs.gravitino.client.oauth2.path", "${your_oauth_server_path}");\nconf.set("fs.gravitino.client.oauth2.scope", "${your_client_scope}");\nPath filesetPath = new Path("gvfs://fileset/test_catalog/test_schema/test_fileset_1");\nFileSystem fs = filesetPath.getFileSystem(conf);\n'})}),"\n",(0,n.jsxs)(t.h5,{id:"using-kerberos-authentication",children:["Using ",(0,n.jsx)(t.code,{children:"Kerberos"})," authentication"]}),"\n",(0,n.jsxs)(t.p,{children:["If you want to use ",(0,n.jsx)(t.code,{children:"kerberos"})," authentication for the Gravitino client in the Gravitino Virtual File System,\nplease refer to this document to complete the configuration of the Gravitino server: ",(0,n.jsx)(t.a,{href:"/docs/0.6.1-incubating/security/security",children:"Security"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"Then, you can configure the Hadoop configuration like this:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-java",children:'Configuration conf = new Configuration();\nconf.set("fs.AbstractFileSystem.gvfs.impl","org.apache.gravitino.filesystem.hadoop.Gvfs");\nconf.set("fs.gvfs.impl","org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");\nconf.set("fs.gravitino.server.uri","http://localhost:8090");\nconf.set("fs.gravitino.client.metalake","test_metalake");\n// Configure the auth type to kerberos.\nconf.set("fs.gravitino.client.authType", "kerberos");\n// Configure the Kerberos configuration.\nconf.set("fs.gravitino.client.kerberos.principal", "${your_kerberos_principal}");\n// Optional. You don\'t need to set the keytab if you use kerberos ticket cache.\nconf.set("fs.gravitino.client.kerberos.keytabFilePath", "${your_kerberos_keytab}");\nPath filesetPath = new Path("gvfs://fileset/test_catalog/test_schema/test_fileset_1");\nFileSystem fs = filesetPath.getFileSystem(conf);\n'})}),"\n",(0,n.jsx)(t.h2,{id:"2-managing-files-of-fileset-with-python-gvfs",children:"2. Managing files of Fileset with Python GVFS"}),"\n",(0,n.jsx)(t.h3,{id:"prerequisites-1",children:"Prerequisites"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["A Hadoop environment with HDFS running. Now we only supports Fileset on HDFS.\nGVFS in Python has been tested against Hadoop 2.7.3. It is recommended to use Hadoop 2.7.3 or later,\nit should work with Hadoop 3.x. Please create an ",(0,n.jsx)(t.a,{href:"https://www.github.com/apache/gravitino/issues",children:"issue"}),"\nif you find any compatibility issues."]}),"\n",(0,n.jsx)(t.li,{children:"Python version >= 3.8. It has been tested GVFS works well with Python 3.8 and Python 3.9.\nYour Python version should be at least higher than Python 3.8."}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["Attention: If you are using macOS or Windows operating system, you need to follow the steps in the\n",(0,n.jsx)(t.a,{href:"https://github.com/apache/hadoop/blob/trunk/BUILDING.txt",children:"Hadoop official building documentation"}),"(Need match your Hadoop version)\nto recompile the native libraries like ",(0,n.jsx)(t.code,{children:"libhdfs"})," and others, and completely replace the files in ",(0,n.jsx)(t.code,{children:"${HADOOP_HOME}/lib/native"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"configuration-1",children:"Configuration"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Configuration item"}),(0,n.jsx)(t.th,{children:"Description"}),(0,n.jsx)(t.th,{children:"Default value"}),(0,n.jsx)(t.th,{children:"Required"}),(0,n.jsx)(t.th,{children:"Since version"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"server_uri"})}),(0,n.jsxs)(t.td,{children:["The Gravitino server uri, e.g. ",(0,n.jsx)(t.code,{children:"http://localhost:8090"}),"."]}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.6.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"metalake_name"})}),(0,n.jsx)(t.td,{children:"The metalake name which the fileset belongs to."}),(0,n.jsx)(t.td,{children:"(none)"}),(0,n.jsx)(t.td,{children:"Yes"}),(0,n.jsx)(t.td,{children:"0.6.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"cache_size"})}),(0,n.jsx)(t.td,{children:"The cache capacity of the Gravitino Virtual File System."}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"20"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.6.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"cache_expired_time"})}),(0,n.jsxs)(t.td,{children:["The value of time that the cache expires after accessing in the Gravitino Virtual File System. The value is in ",(0,n.jsx)(t.code,{children:"seconds"}),"."]}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"3600"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.6.0"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"auth_type"})}),(0,n.jsxs)(t.td,{children:["The auth type to initialize the Gravitino client to use with the Gravitino Virtual File System. Currently only supports ",(0,n.jsx)(t.code,{children:"simple"})," auth types."]}),(0,n.jsx)(t.td,{children:(0,n.jsx)(t.code,{children:"simple"})}),(0,n.jsx)(t.td,{children:"No"}),(0,n.jsx)(t.td,{children:"0.6.0"})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["You can configure these properties when obtaining the ",(0,n.jsx)(t.code,{children:"Gravitino Virtual FileSystem"})," in Python like this:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'from gravitino import gvfs\noptions = {\n    "cache_size": 20,\n    "cache_expired_time": 3600,\n    "auth_type": "simple"\n}\nfs = gvfs.GravitinoVirtualFileSystem(server_uri="http://localhost:8090", metalake_name="test_metalake", options=options)\n'})}),"\n",(0,n.jsx)(t.h3,{id:"usage-examples-1",children:"Usage examples"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Make sure to obtain the Gravitino library.\nYou can get it by ",(0,n.jsx)(t.a,{href:"https://pip.pypa.io/en/stable/installation/",children:"pip"}),":"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"pip install apache-gravitino\n"})}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Configuring the Hadoop environment.\nYou should ensure that the Python client has Kerberos authentication information and\nconfigure Hadoop environments in the system environment:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"# kinit kerberos\nkinit -kt /tmp/xxx.keytab xxx@HADOOP.COM\n# Or you can configure kerberos information in the Hadoop `core-site.xml` file\n<property>\n  <name>hadoop.security.authentication</name>\n  <value>kerberos</value>\n</property>\n\n<property>\n  <name>hadoop.client.kerberos.principal</name>\n  <value>xxx@HADOOP.COM</value>\n</property>\n\n<property>\n  <name>hadoop.client.keytab.file</name>\n  <value>/tmp/xxx.keytab</value>\n</property>\n# Configure Hadoop env in Linux\nexport HADOOP_HOME=${YOUR_HADOOP_PATH}\nexport HADOOP_CONF_DIR=${YOUR_HADOOP_PATH}/etc/hadoop\nexport CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`\n"})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"via-fsspec-style-interface",children:"Via fsspec-style interface"}),"\n",(0,n.jsx)(t.p,{children:"You can use the fsspec-style interface to perform operations on the fileset files."}),"\n",(0,n.jsx)(t.p,{children:"For example:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'from gravitino import gvfs\n\n# init the gvfs\nfs = gvfs.GravitinoVirtualFileSystem(server_uri="http://localhost:8090", metalake_name="test_metalake")\n\n# list file infos under the fileset\nfs.ls(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir")\n\n# get file info under the fileset\nfs.info(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test.parquet")\n\n# check a file or a diretory whether exists\nfs.exists(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir")\n\n# write something into a file\nwith fs.open(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test.txt", mode="wb") as output_stream:\n    output_stream.write(b"hello world")\n\n# append something into a file\nwith fs.open(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test.txt", mode="ab") as append_stream:\n    append_stream.write(b"hello world")\n\n# read something from a file\nwith fs.open(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test.txt", mode="rb") as input_stream:\n    input_stream.read()\n\n# copy a file\nfs.cp_file(path1="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test.txt",\n           path2="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test-1.txt")\n\n# delete a file\nfs.rm_file(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/ttt/test-1.txt")\n\n# two methods to create a directory\nfs.makedirs(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir_2")\n\nfs.mkdir(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir_3")\n\n# delete a file or a directory recursively\nfs.rm(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir_2", recursive=True)\n\n# delete a directory\nfs.rmdir(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir_2")\n\n# move a file or a directory\nfs.mv(path1="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test-1.txt",\n      path2="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/sub_dir/test-2.txt")\n\n# get the content of a file\nfs.cat_file(path="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test-1.txt")\n\n# copy a remote file to local\nfs.get_file(rpath="gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test-1.txt",\n            lpath="/tmp/local-file-1.txt")\n'})}),"\n",(0,n.jsx)(t.h4,{id:"integrating-with-third-party-python-libraries",children:"Integrating with Third-party Python libraries"}),"\n",(0,n.jsx)(t.p,{children:"You can also perform operations on the files or directories managed by fileset\nintegrating with some Third-party Python libraries which support fsspec compatible filesystems."}),"\n",(0,n.jsx)(t.p,{children:"For example:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["Integrating with ",(0,n.jsx)(t.a,{href:"https://pandas.pydata.org/docs/reference/io.html",children:"Pandas"}),"(2.0.3)."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"from gravitino import gvfs\nimport pandas as pd\n\ndata = pd.DataFrame({'Name': ['A', 'B', 'C', 'D'], 'ID': [20, 21, 19, 18]})\nstorage_options = {'server_uri': 'http://localhost:8090', 'metalake_name': 'test_metalake'}\n# save data to a parquet file under the fileset\ndata.to_parquet('gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.parquet', storage_options=storage_options)\n\n# read data from a parquet file under the fileset\nds = pd.read_parquet(path=\"gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.parquet\",\n                     storage_options=storage_options)\nprint(ds)\n\n# save data to a csv file under the fileset\ndata.to_csv('gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.csv', storage_options=storage_options)\n\n# save data from a csv file under the fileset\ndf = pd.read_csv('gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.csv', storage_options=storage_options)\nprint(df)\n"})}),"\n",(0,n.jsxs)(t.ol,{start:"2",children:["\n",(0,n.jsxs)(t.li,{children:["Integrating with ",(0,n.jsx)(t.a,{href:"https://arrow.apache.org/docs/python/filesystems.html",children:"PyArrow"}),"(15.0.2)."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'from gravitino import gvfs\nimport pyarrow.dataset as dt\nimport pyarrow.parquet as pq\n\nfs = gvfs.GravitinoVirtualFileSystem(\n    server_uri="http://localhost:8090", metalake_name="test_metalake"\n)\n\n# read a parquet file as arrow dataset\narrow_dataset = dt.dataset("gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.parquet", filesystem=fs)\n\n# read a parquet file as arrow parquet table\narrow_table = pq.read_table("gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.parquet", filesystem=fs)\n'})}),"\n",(0,n.jsxs)(t.ol,{start:"3",children:["\n",(0,n.jsxs)(t.li,{children:["Integrating with ",(0,n.jsx)(t.a,{href:"https://docs.ray.io/en/latest/data/loading-data.html#loading-data",children:"Ray"}),"(2.10.0)."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'from gravitino import gvfs\nimport ray\n\nfs = gvfs.GravitinoVirtualFileSystem(\n    server_uri="http://localhost:8090", metalake_name="test_metalake"\n)\n\n# read a parquet file as ray dataset\nds = ray.data.read_parquet("gvfs://fileset/fileset_catalog/tmp/tmp_fileset/test.parquet",fs)\n'})}),"\n",(0,n.jsxs)(t.ol,{start:"4",children:["\n",(0,n.jsxs)(t.li,{children:["Integrating with ",(0,n.jsx)(t.a,{href:"https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/#support-for-external-filesystems",children:"LlamaIndex"}),"(0.10.40)."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"from gravitino import gvfs\nfrom llama_index.core import SimpleDirectoryReader\n\nfs = gvfs.GravitinoVirtualFileSystem(server_uri=server_uri, metalake_name=metalake_name)\n\n# read all document files like csv files under the fileset sub dir\nreader = SimpleDirectoryReader(\n    input_dir='fileset/fileset_catalog/tmp/tmp_fileset/sub_dir',\n    fs=fs,\n    recursive=True,  # recursively searches all subdirectories\n)\ndocuments = reader.load_data()\nprint(documents)\n"})}),"\n",(0,n.jsx)(t.h3,{id:"authentication-1",children:"Authentication"}),"\n",(0,n.jsxs)(t.p,{children:["Currently, Gravitino Virtual File System in Python only supports one kind of authentication types to access Gravitino server: ",(0,n.jsx)(t.code,{children:"simple"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["The type of ",(0,n.jsx)(t.code,{children:"simple"})," is the default authentication type in Gravitino Virtual File System in Python."]}),"\n",(0,n.jsx)(t.h4,{id:"how-to-use-authentication-1",children:"How to use authentication"}),"\n",(0,n.jsxs)(t.h5,{id:"using-simple-authentication-1",children:["Using ",(0,n.jsx)(t.code,{children:"simple"})," authentication"]}),"\n",(0,n.jsxs)(t.p,{children:["First, make sure that your Gravitino server is also configured to use the ",(0,n.jsx)(t.code,{children:"simple"})," authentication mode."]}),"\n",(0,n.jsx)(t.p,{children:"Then, you can configure the authentication like this:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'from gravitino import gvfs\n\noptions = {"auth_type": "simple"}\nfs = gvfs.GravitinoVirtualFileSystem(server_uri="http://localhost:8090", metalake_name="test_metalake", options=options)\nprint(fs.ls("gvfs://fileset/fileset_catlaog/tmp/test_fileset"))\n'})})]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}}}]);